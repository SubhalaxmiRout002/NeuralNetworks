{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARY IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# Components for building the layered CNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "# The ImageDataGenerator will carry out the flow of image data from storage to memory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Set the base directory for the dataset\n",
    "# Assume the dataset is present and the folder structure matches what is expected\n",
    "src = 'Dataset/PetImages/'\n",
    "\n",
    "# Import the function for splitting the dataset into the training set and the testing set\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dataset_utilities import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARTITION DATASET INTO TRAINING SET AND TESTING SET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning the dataset into the training set and testing set...\n"
     ]
    }
   ],
   "source": [
    "# Create separate folders for storing the training samples and the test samples\n",
    "#if not os.path.isdir(src + 'Train/'):\n",
    "\n",
    "# Partition the dataset\n",
    "print(\"Partitioning the dataset into the training set and testing set...\")\n",
    "train_test_split(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD AND COMPILE THE CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "FILTER_SIZE = 3                         # This is the sliding window that will scan an image and create a feature set\n",
    "NUM_FILTERS = 32                        # We will use a total of 32 filters\n",
    "INPUT_SIZE  = 64                        # Compress image dimensions to 32 x 32 (may lose some data)\n",
    "MAXPOOL_SIZE = 2                        # 2 x 2 max pooling size halves the input dimensions\n",
    "BATCH_SIZE = 16                         # Use 16 training samples per batch\n",
    "STEPS_PER_EPOCH = 20000//BATCH_SIZE     # Number of iterations per epoch; the '//' operator divides, but truncates the decimal\n",
    "EPOCHS = 10                             # Use 10 epochs\n",
    "\n",
    "# Start with base sequential layer model\n",
    "model = Sequential()\n",
    "\n",
    "# Add first 2D convolutional layer; this layer reads the actual image files\n",
    "model.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE), input_shape = (INPUT_SIZE, INPUT_SIZE, 3), activation = 'relu'))\n",
    "\n",
    "# Add first subsampling layer using max pooling\n",
    "model.add(AveragePooling2D(pool_size = (MAXPOOL_SIZE, MAXPOOL_SIZE)))\n",
    "\n",
    "# Add second 2D convolutional layer; this layer reads the subsampled feature map from the first convolutional layer\n",
    "model.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE), activation = 'relu'))\n",
    "\n",
    "# Add second subsampling layer, also using max pooling\n",
    "model.add(AveragePooling2D(pool_size = (MAXPOOL_SIZE, MAXPOOL_SIZE)))\n",
    "\n",
    "# Flatten the multidmensional vector received from the second subsampling layer into a one-dimensional vector\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense fully connected layer with 128 nodes\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "# Add dropout layer to help reduce overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add second fully connected layer, with only a single node and using a sigmoid activation function\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compile model using adam optimizer and binary cross-entropy loss function\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19997 images belonging to 2 classes.\n",
      "Training the CNN...\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 83s 66ms/step - loss: 0.6520 - accuracy: 0.6188\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 82s 66ms/step - loss: 0.5846 - accuracy: 0.6963\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 82s 65ms/step - loss: 0.5216 - accuracy: 0.7450\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 83s 66ms/step - loss: 0.4740 - accuracy: 0.7733\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 82s 65ms/step - loss: 0.4347 - accuracy: 0.8023\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 82s 66ms/step - loss: 0.3935 - accuracy: 0.8231\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 83s 66ms/step - loss: 0.3564 - accuracy: 0.8431\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 83s 66ms/step - loss: 0.3111 - accuracy: 0.8653\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 83s 66ms/step - loss: 0.2787 - accuracy: 0.8838\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 82s 66ms/step - loss: 0.2416 - accuracy: 0.9032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd31cf37990>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ImageDataGenerator to load batches of images at a time into memory\n",
    "training_data_generator = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Create batch-loaded training set\n",
    "training_set = training_data_generator.flow_from_directory(src + 'Train/',\n",
    "                                                target_size = (INPUT_SIZE, INPUT_SIZE),\n",
    "                                                batch_size = BATCH_SIZE,\n",
    "                                                class_mode = 'binary')\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the CNN...\")\n",
    "model.fit_generator(training_set, steps_per_epoch = STEPS_PER_EPOCH, epochs = EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n",
      "Testing the CNN...\n"
     ]
    }
   ],
   "source": [
    "# Create ImageDataGenerator to load batches of images at a time into memory\n",
    "testing_data_generator = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Create batch-loaded testing set\n",
    "test_set = testing_data_generator.flow_from_directory(src + 'Test/',\n",
    "                                             target_size = (INPUT_SIZE, INPUT_SIZE),\n",
    "                                             batch_size = BATCH_SIZE,\n",
    "                                             class_mode = 'binary')\n",
    "\n",
    "# Test the model\n",
    "print(\"Testing the CNN...\")\n",
    "score = model.evaluate_generator(test_set, steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:\n",
      "loss: 0.5438082218170166\n",
      "accuracy: 0.7850000262260437\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"RESULTS:\")\n",
    "for idx, metric in enumerate(model.metrics_names):\n",
    "    print(\"{}: {}\".format(metric, score[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has below parameters:\n",
    "\n",
    "FILTER_SIZE = 3                         \n",
    "NUM_FILTERS = 32                        \n",
    "INPUT_SIZE  = 64                        \n",
    "MAXPOOL_SIZE = 2                        \n",
    "BATCH_SIZE = 16                         \n",
    "STEPS_PER_EPOCH = 20000//BATCH_SIZE \n",
    "EPOCHS = 10\n",
    "\n",
    "The model used average pooling layers instead of the max-pooling subsampling layers and has 2 convolution layers.\n",
    "\n",
    "The accuracy has gone down from 79% (original model) to 78% and loss went up from 50% to 54%.\n",
    "\n",
    "Above CNN shows accuracy: 78.5%\n",
    "Loss: 54.38% \n",
    "\n",
    "The model performs poorly than the original CNN model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
