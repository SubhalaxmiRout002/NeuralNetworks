{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Recurrent Network for Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARY IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET AND CREATE MAP OF UNIQUE CHARACTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  7353\n",
      "Total Vocab:  32\n"
     ]
    }
   ],
   "source": [
    "# Load the text corpus\n",
    "filename = \"Cat_in_the_Hat.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "\n",
    "# Convert all the text to lowercase\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "# Create a map that maps each unique character in the text to a unique integer value\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "# Display the total number of characters (n_chars) and the vocabulary (the number of unique characters)\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE TRAINING PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  7253\n"
     ]
    }
   ],
   "source": [
    "# Create the patterns to be used for training\n",
    "seq_length = 100 # fixed length sliding window for training pattern\n",
    "dataX = [] # input sequences\n",
    "dataY = [] # outputs\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORM DATA TO BE SUITABLE FOR KERAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape dataX to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# Rescale integers mapped to characters to the range 0-to-1 to accommodate learning using sigmoid function\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# One hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD THE LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequential model containing 2 LSTM layers and 2 Dropout layers, followed by a dense output layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model using the Adam optimizer and categorical crossentropy for the loss function\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Define the checkpoint; i.e., saved past state of the model\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 3.0295\n",
      "Epoch 00001: loss improved from inf to 3.02948, saving model to weights-improvement-01-3.0295-bigger.hdf5\n",
      "114/114 [==============================] - 108s 901ms/step - loss: 3.0295\n",
      "Epoch 2/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.9913\n",
      "Epoch 00002: loss improved from 3.02948 to 2.99128, saving model to weights-improvement-02-2.9913-bigger.hdf5\n",
      "114/114 [==============================] - 111s 976ms/step - loss: 2.9913\n",
      "Epoch 3/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.9542\n",
      "Epoch 00003: loss improved from 2.99128 to 2.95423, saving model to weights-improvement-03-2.9542-bigger.hdf5\n",
      "114/114 [==============================] - 103s 903ms/step - loss: 2.9542\n",
      "Epoch 4/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.8381\n",
      "Epoch 00004: loss improved from 2.95423 to 2.83814, saving model to weights-improvement-04-2.8381-bigger.hdf5\n",
      "114/114 [==============================] - 101s 881ms/step - loss: 2.8381\n",
      "Epoch 5/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.7329\n",
      "Epoch 00005: loss improved from 2.83814 to 2.73289, saving model to weights-improvement-05-2.7329-bigger.hdf5\n",
      "114/114 [==============================] - 100s 879ms/step - loss: 2.7329\n",
      "Epoch 6/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.6079\n",
      "Epoch 00006: loss improved from 2.73289 to 2.60794, saving model to weights-improvement-06-2.6079-bigger.hdf5\n",
      "114/114 [==============================] - 100s 878ms/step - loss: 2.6079\n",
      "Epoch 7/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.4796\n",
      "Epoch 00007: loss improved from 2.60794 to 2.47958, saving model to weights-improvement-07-2.4796-bigger.hdf5\n",
      "114/114 [==============================] - 101s 884ms/step - loss: 2.4796\n",
      "Epoch 8/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.3703\n",
      "Epoch 00008: loss improved from 2.47958 to 2.37028, saving model to weights-improvement-08-2.3703-bigger.hdf5\n",
      "114/114 [==============================] - 103s 900ms/step - loss: 2.3703\n",
      "Epoch 9/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.2571\n",
      "Epoch 00009: loss improved from 2.37028 to 2.25711, saving model to weights-improvement-09-2.2571-bigger.hdf5\n",
      "114/114 [==============================] - 100s 881ms/step - loss: 2.2571\n",
      "Epoch 10/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.1681\n",
      "Epoch 00010: loss improved from 2.25711 to 2.16814, saving model to weights-improvement-10-2.1681-bigger.hdf5\n",
      "114/114 [==============================] - 103s 905ms/step - loss: 2.1681\n",
      "Epoch 11/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.0826\n",
      "Epoch 00011: loss improved from 2.16814 to 2.08264, saving model to weights-improvement-11-2.0826-bigger.hdf5\n",
      "114/114 [==============================] - 102s 897ms/step - loss: 2.0826\n",
      "Epoch 12/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.9808\n",
      "Epoch 00012: loss improved from 2.08264 to 1.98081, saving model to weights-improvement-12-1.9808-bigger.hdf5\n",
      "114/114 [==============================] - 101s 888ms/step - loss: 1.9808\n",
      "Epoch 13/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.8784\n",
      "Epoch 00013: loss improved from 1.98081 to 1.87845, saving model to weights-improvement-13-1.8784-bigger.hdf5\n",
      "114/114 [==============================] - 103s 900ms/step - loss: 1.8784\n",
      "Epoch 14/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.7774\n",
      "Epoch 00014: loss improved from 1.87845 to 1.77736, saving model to weights-improvement-14-1.7774-bigger.hdf5\n",
      "114/114 [==============================] - 102s 893ms/step - loss: 1.7774\n",
      "Epoch 15/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.6899\n",
      "Epoch 00015: loss improved from 1.77736 to 1.68985, saving model to weights-improvement-15-1.6899-bigger.hdf5\n",
      "114/114 [==============================] - 436s 4s/step - loss: 1.6899\n",
      "Epoch 16/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.5778\n",
      "Epoch 00016: loss improved from 1.68985 to 1.57779, saving model to weights-improvement-16-1.5778-bigger.hdf5\n",
      "114/114 [==============================] - 101s 891ms/step - loss: 1.5778\n",
      "Epoch 17/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.4828\n",
      "Epoch 00017: loss improved from 1.57779 to 1.48280, saving model to weights-improvement-17-1.4828-bigger.hdf5\n",
      "114/114 [==============================] - 101s 890ms/step - loss: 1.4828\n",
      "Epoch 18/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.3890\n",
      "Epoch 00018: loss improved from 1.48280 to 1.38903, saving model to weights-improvement-18-1.3890-bigger.hdf5\n",
      "114/114 [==============================] - 100s 879ms/step - loss: 1.3890\n",
      "Epoch 19/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.2979\n",
      "Epoch 00019: loss improved from 1.38903 to 1.29787, saving model to weights-improvement-19-1.2979-bigger.hdf5\n",
      "114/114 [==============================] - 101s 882ms/step - loss: 1.2979\n",
      "Epoch 20/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.2031\n",
      "Epoch 00020: loss improved from 1.29787 to 1.20314, saving model to weights-improvement-20-1.2031-bigger.hdf5\n",
      "114/114 [==============================] - 100s 873ms/step - loss: 1.2031\n",
      "Epoch 21/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.1193\n",
      "Epoch 00021: loss improved from 1.20314 to 1.11934, saving model to weights-improvement-21-1.1193-bigger.hdf5\n",
      "114/114 [==============================] - 100s 874ms/step - loss: 1.1193\n",
      "Epoch 22/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.0320\n",
      "Epoch 00022: loss improved from 1.11934 to 1.03196, saving model to weights-improvement-22-1.0320-bigger.hdf5\n",
      "114/114 [==============================] - 372s 3s/step - loss: 1.0320\n",
      "Epoch 23/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.9593 \n",
      "Epoch 00023: loss improved from 1.03196 to 0.95935, saving model to weights-improvement-23-0.9593-bigger.hdf5\n",
      "114/114 [==============================] - 1589s 14s/step - loss: 0.9593\n",
      "Epoch 24/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.8672\n",
      "Epoch 00024: loss improved from 0.95935 to 0.86719, saving model to weights-improvement-24-0.8672-bigger.hdf5\n",
      "114/114 [==============================] - 139s 1s/step - loss: 0.8672\n",
      "Epoch 25/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.8203\n",
      "Epoch 00025: loss improved from 0.86719 to 0.82026, saving model to weights-improvement-25-0.8203-bigger.hdf5\n",
      "114/114 [==============================] - 132s 1s/step - loss: 0.8203\n",
      "Epoch 26/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.7494\n",
      "Epoch 00026: loss improved from 0.82026 to 0.74937, saving model to weights-improvement-26-0.7494-bigger.hdf5\n",
      "114/114 [==============================] - 131s 1s/step - loss: 0.7494\n",
      "Epoch 27/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.6922\n",
      "Epoch 00027: loss improved from 0.74937 to 0.69223, saving model to weights-improvement-27-0.6922-bigger.hdf5\n",
      "114/114 [==============================] - 134s 1s/step - loss: 0.6922\n",
      "Epoch 28/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.6299\n",
      "Epoch 00028: loss improved from 0.69223 to 0.62993, saving model to weights-improvement-28-0.6299-bigger.hdf5\n",
      "114/114 [==============================] - 133s 1s/step - loss: 0.6299\n",
      "Epoch 29/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.5749\n",
      "Epoch 00029: loss improved from 0.62993 to 0.57493, saving model to weights-improvement-29-0.5749-bigger.hdf5\n",
      "114/114 [==============================] - 129s 1s/step - loss: 0.5749\n",
      "Epoch 30/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.5221\n",
      "Epoch 00030: loss improved from 0.57493 to 0.52208, saving model to weights-improvement-30-0.5221-bigger.hdf5\n",
      "114/114 [==============================] - 126s 1s/step - loss: 0.5221\n",
      "Epoch 31/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.4787\n",
      "Epoch 00031: loss improved from 0.52208 to 0.47866, saving model to weights-improvement-31-0.4787-bigger.hdf5\n",
      "114/114 [==============================] - 104s 908ms/step - loss: 0.4787\n",
      "Epoch 32/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.4581\n",
      "Epoch 00032: loss improved from 0.47866 to 0.45807, saving model to weights-improvement-32-0.4581-bigger.hdf5\n",
      "114/114 [==============================] - 100s 879ms/step - loss: 0.4581\n",
      "Epoch 33/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.4002\n",
      "Epoch 00033: loss improved from 0.45807 to 0.40021, saving model to weights-improvement-33-0.4002-bigger.hdf5\n",
      "114/114 [==============================] - 99s 871ms/step - loss: 0.4002\n",
      "Epoch 34/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.3689\n",
      "Epoch 00034: loss improved from 0.40021 to 0.36889, saving model to weights-improvement-34-0.3689-bigger.hdf5\n",
      "114/114 [==============================] - 101s 889ms/step - loss: 0.3689\n",
      "Epoch 35/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.3424\n",
      "Epoch 00035: loss improved from 0.36889 to 0.34243, saving model to weights-improvement-35-0.3424-bigger.hdf5\n",
      "114/114 [==============================] - 101s 882ms/step - loss: 0.3424\n",
      "Epoch 36/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.3139\n",
      "Epoch 00036: loss improved from 0.34243 to 0.31395, saving model to weights-improvement-36-0.3139-bigger.hdf5\n",
      "114/114 [==============================] - 101s 888ms/step - loss: 0.3139\n",
      "Epoch 37/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.2887\n",
      "Epoch 00037: loss improved from 0.31395 to 0.28866, saving model to weights-improvement-37-0.2887-bigger.hdf5\n",
      "114/114 [==============================] - 102s 891ms/step - loss: 0.2887\n",
      "Epoch 38/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.2627\n",
      "Epoch 00038: loss improved from 0.28866 to 0.26272, saving model to weights-improvement-38-0.2627-bigger.hdf5\n",
      "114/114 [==============================] - 100s 879ms/step - loss: 0.2627\n",
      "Epoch 39/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.2496\n",
      "Epoch 00039: loss improved from 0.26272 to 0.24958, saving model to weights-improvement-39-0.2496-bigger.hdf5\n",
      "114/114 [==============================] - 105s 921ms/step - loss: 0.2496\n",
      "Epoch 40/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.2320\n",
      "Epoch 00040: loss improved from 0.24958 to 0.23198, saving model to weights-improvement-40-0.2320-bigger.hdf5\n",
      "114/114 [==============================] - 100s 879ms/step - loss: 0.2320\n",
      "Epoch 41/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.2085\n",
      "Epoch 00041: loss improved from 0.23198 to 0.20848, saving model to weights-improvement-41-0.2085-bigger.hdf5\n",
      "114/114 [==============================] - 106s 927ms/step - loss: 0.2085\n",
      "Epoch 42/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1948\n",
      "Epoch 00042: loss improved from 0.20848 to 0.19477, saving model to weights-improvement-42-0.1948-bigger.hdf5\n",
      "114/114 [==============================] - 99s 865ms/step - loss: 0.1948\n",
      "Epoch 43/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1809\n",
      "Epoch 00043: loss improved from 0.19477 to 0.18088, saving model to weights-improvement-43-0.1809-bigger.hdf5\n",
      "114/114 [==============================] - 100s 878ms/step - loss: 0.1809\n",
      "Epoch 44/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1715\n",
      "Epoch 00044: loss improved from 0.18088 to 0.17153, saving model to weights-improvement-44-0.1715-bigger.hdf5\n",
      "114/114 [==============================] - 102s 895ms/step - loss: 0.1715\n",
      "Epoch 45/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1586\n",
      "Epoch 00045: loss improved from 0.17153 to 0.15863, saving model to weights-improvement-45-0.1586-bigger.hdf5\n",
      "114/114 [==============================] - 100s 875ms/step - loss: 0.1586\n",
      "Epoch 46/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1508\n",
      "Epoch 00046: loss improved from 0.15863 to 0.15077, saving model to weights-improvement-46-0.1508-bigger.hdf5\n",
      "114/114 [==============================] - 99s 867ms/step - loss: 0.1508\n",
      "Epoch 47/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1345\n",
      "Epoch 00047: loss improved from 0.15077 to 0.13448, saving model to weights-improvement-47-0.1345-bigger.hdf5\n",
      "114/114 [==============================] - 102s 896ms/step - loss: 0.1345\n",
      "Epoch 48/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1350\n",
      "Epoch 00048: loss did not improve from 0.13448\n",
      "114/114 [==============================] - 102s 894ms/step - loss: 0.1350\n",
      "Epoch 49/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1415\n",
      "Epoch 00049: loss did not improve from 0.13448\n",
      "114/114 [==============================] - 108s 943ms/step - loss: 0.1415\n",
      "Epoch 50/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1245\n",
      "Epoch 00050: loss improved from 0.13448 to 0.12450, saving model to weights-improvement-50-0.1245-bigger.hdf5\n",
      "114/114 [==============================] - 105s 923ms/step - loss: 0.1245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe1efc795d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
