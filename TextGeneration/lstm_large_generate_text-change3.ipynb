{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET AND CREATE MAP OF UNIQUE CHARACTERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  6905\n",
      "Total Vocab:  26\n"
     ]
    }
   ],
   "source": [
    "# Load the text corpus\n",
    "filename = \"Cat_in_the_Hat.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "\n",
    "# Convert all the text to lowercase\n",
    "raw_text = \"\".join(v for v in raw_text if v not in string.punctuation).lower()\n",
    "\n",
    "# Create a map that maps each unique character in the text to a unique integer value\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "# Also create a reverse map to be able to output the character that maps to a specific integer\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Display the total number of characters (n_chars) and the vocabulary (the number of unique characters)\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE TRAINING PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  6805\n"
     ]
    }
   ],
   "source": [
    "# Create the patterns to be used for training\n",
    "seq_length = 100 # fixed length sliding window for training pattern\n",
    "dataX = [] # input sequences\n",
    "dataY = [] # outputs\n",
    "\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORM DATA TO BE SUITABLE FOR KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape dataX to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# Rescale integers mapped to characters to the range 0-to-1 to accommodate learning using sigmoid function\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# One hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD THE LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequential model containing 2 LSTM layers and 2 Dropout layers, followed by a dense output layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD THE SAVED NETWORK WEIGHTS FROM CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the network weights from the specified checkpoint file\n",
    "filename = \"weights-improvement-50-0.0991-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "\n",
    "# Compile the model using the Adam optimizer and categorical crossentropy for the loss function\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" the cat said\n",
      "then he fell on his head\n",
      "he came down with a bump\n",
      "from up there on the ball\n",
      "and sally a \"\n",
      "nd i\n",
      "we saw all the things fall\n",
      "\n",
      "and our fish came down too\n",
      "he fell into a pot\n",
      "he said do i like this\n",
      "oh no i do not\n",
      "this is not a good game\n",
      "said our fish as he lit\n",
      "no i do not like it\n",
      "not one little bit\n",
      "\n",
      "and then something went bump\n",
      "how that bump made us jump\n",
      "we looked\n",
      "then we saw him step in on the mat\n",
      "we looked\n",
      "and we saw him\n",
      "she cat in the hat\n",
      "and he said to us\n",
      "why do you sit there like that\n",
      "i know it is wet\n",
      "and the sun is not sunny\n",
      "but we can have\n",
      "lots of good fun if you wish\n",
      "with a game that i call\n",
      "upupup with a fish\n",
      "\n",
      "put me down said the fish\n",
      "i do not wish to fall\n",
      "\n",
      "have no fear said the cat\n",
      "you did not like our game\n",
      "oh dear\n",
      "what a shame\n",
      "what a shame\n",
      "what a shame\n",
      "\n",
      "then he shut up the things\n",
      "in the box with the hook\n",
      "and the cat went away\n",
      "with a sad kind of look\n",
      "\n",
      "that is good said the fish\n",
      "h do not wish to fall\n",
      "\n",
      "have no fear said the cat\n",
      "you did not like our game\n",
      "oh dear\n",
      "what a shame\n",
      "what a shame\n",
      "what a shame\n",
      "\n",
      "then he shut up the things\n",
      "in the box with the hook\n",
      "and the cat went awa\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Pick a random seed and display it\n",
    "start = numpy.random.randint(0, len(dataX) - 1)\n",
    "\n",
    "pattern = dataX[start]\n",
    "\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# Generate 1000 characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "# Text generation complete\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model removed punctuations from the text.**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
