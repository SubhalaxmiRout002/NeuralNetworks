{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Recurrent Network for Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARY IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET AND CREATE MAP OF UNIQUE CHARACTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  7353\n",
      "Total Vocab:  32\n"
     ]
    }
   ],
   "source": [
    "# Load the text corpus\n",
    "filename = \"Cat_in_the_Hat.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "\n",
    "# Convert all the text to lowercase\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "# Create a map that maps each unique character in the text to a unique integer value\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "# Display the total number of characters (n_chars) and the vocabulary (the number of unique characters)\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE TRAINING PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  7253\n"
     ]
    }
   ],
   "source": [
    "# Create the patterns to be used for training\n",
    "seq_length = 100 # fixed length sliding window for training pattern\n",
    "dataX = [] # input sequences\n",
    "dataY = [] # outputs\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORM DATA TO BE SUITABLE FOR KERAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape dataX to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# Rescale integers mapped to characters to the range 0-to-1 to accommodate learning using sigmoid function\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# One hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD THE LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequential model containing 1 LSTM layers and 1 Dropout layers, followed by a dense output layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model using the Adam optimizer and categorical crossentropy for the loss function\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Define the checkpoint; i.e., saved past state of the model\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 3.0272\n",
      "Epoch 00001: loss improved from inf to 3.02716, saving model to weights-improvement-01-3.0272-bigger.hdf5\n",
      "114/114 [==============================] - 50s 412ms/step - loss: 3.0272\n",
      "Epoch 2/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.9878\n",
      "Epoch 00002: loss improved from 3.02716 to 2.98784, saving model to weights-improvement-02-2.9878-bigger.hdf5\n",
      "114/114 [==============================] - 48s 421ms/step - loss: 2.9878\n",
      "Epoch 3/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.9477\n",
      "Epoch 00003: loss improved from 2.98784 to 2.94766, saving model to weights-improvement-03-2.9477-bigger.hdf5\n",
      "114/114 [==============================] - 47s 411ms/step - loss: 2.9477\n",
      "Epoch 4/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.8347\n",
      "Epoch 00004: loss improved from 2.94766 to 2.83470, saving model to weights-improvement-04-2.8347-bigger.hdf5\n",
      "114/114 [==============================] - 51s 450ms/step - loss: 2.8347\n",
      "Epoch 5/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.7197\n",
      "Epoch 00005: loss improved from 2.83470 to 2.71973, saving model to weights-improvement-05-2.7197-bigger.hdf5\n",
      "114/114 [==============================] - 56s 490ms/step - loss: 2.7197\n",
      "Epoch 6/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.5918\n",
      "Epoch 00006: loss improved from 2.71973 to 2.59181, saving model to weights-improvement-06-2.5918-bigger.hdf5\n",
      "114/114 [==============================] - 45s 399ms/step - loss: 2.5918\n",
      "Epoch 7/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.4674\n",
      "Epoch 00007: loss improved from 2.59181 to 2.46738, saving model to weights-improvement-07-2.4674-bigger.hdf5\n",
      "114/114 [==============================] - 46s 400ms/step - loss: 2.4674\n",
      "Epoch 8/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.3571\n",
      "Epoch 00008: loss improved from 2.46738 to 2.35715, saving model to weights-improvement-08-2.3571-bigger.hdf5\n",
      "114/114 [==============================] - 46s 399ms/step - loss: 2.3571\n",
      "Epoch 9/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.2583\n",
      "Epoch 00009: loss improved from 2.35715 to 2.25833, saving model to weights-improvement-09-2.2583-bigger.hdf5\n",
      "114/114 [==============================] - 45s 398ms/step - loss: 2.2583\n",
      "Epoch 10/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.1676\n",
      "Epoch 00010: loss improved from 2.25833 to 2.16764, saving model to weights-improvement-10-2.1676-bigger.hdf5\n",
      "114/114 [==============================] - 46s 401ms/step - loss: 2.1676\n",
      "Epoch 11/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 2.0670\n",
      "Epoch 00011: loss improved from 2.16764 to 2.06697, saving model to weights-improvement-11-2.0670-bigger.hdf5\n",
      "114/114 [==============================] - 46s 400ms/step - loss: 2.0670\n",
      "Epoch 12/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.9802\n",
      "Epoch 00012: loss improved from 2.06697 to 1.98025, saving model to weights-improvement-12-1.9802-bigger.hdf5\n",
      "114/114 [==============================] - 46s 402ms/step - loss: 1.9802\n",
      "Epoch 13/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.8749\n",
      "Epoch 00013: loss improved from 1.98025 to 1.87485, saving model to weights-improvement-13-1.8749-bigger.hdf5\n",
      "114/114 [==============================] - 46s 399ms/step - loss: 1.8749\n",
      "Epoch 14/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.7602\n",
      "Epoch 00014: loss improved from 1.87485 to 1.76020, saving model to weights-improvement-14-1.7602-bigger.hdf5\n",
      "114/114 [==============================] - 46s 399ms/step - loss: 1.7602\n",
      "Epoch 15/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.6689\n",
      "Epoch 00015: loss improved from 1.76020 to 1.66892, saving model to weights-improvement-15-1.6689-bigger.hdf5\n",
      "114/114 [==============================] - 46s 399ms/step - loss: 1.6689\n",
      "Epoch 16/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.5679\n",
      "Epoch 00016: loss improved from 1.66892 to 1.56790, saving model to weights-improvement-16-1.5679-bigger.hdf5\n",
      "114/114 [==============================] - 46s 399ms/step - loss: 1.5679\n",
      "Epoch 17/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.4650\n",
      "Epoch 00017: loss improved from 1.56790 to 1.46498, saving model to weights-improvement-17-1.4650-bigger.hdf5\n",
      "114/114 [==============================] - 46s 400ms/step - loss: 1.4650\n",
      "Epoch 18/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.3823\n",
      "Epoch 00018: loss improved from 1.46498 to 1.38226, saving model to weights-improvement-18-1.3823-bigger.hdf5\n",
      "114/114 [==============================] - 46s 401ms/step - loss: 1.3823\n",
      "Epoch 19/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.2719\n",
      "Epoch 00019: loss improved from 1.38226 to 1.27188, saving model to weights-improvement-19-1.2719-bigger.hdf5\n",
      "114/114 [==============================] - 45s 394ms/step - loss: 1.2719\n",
      "Epoch 20/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.1835\n",
      "Epoch 00020: loss improved from 1.27188 to 1.18355, saving model to weights-improvement-20-1.1835-bigger.hdf5\n",
      "114/114 [==============================] - 42s 369ms/step - loss: 1.1835\n",
      "Epoch 21/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.0983\n",
      "Epoch 00021: loss improved from 1.18355 to 1.09826, saving model to weights-improvement-21-1.0983-bigger.hdf5\n",
      "114/114 [==============================] - 40s 354ms/step - loss: 1.0983\n",
      "Epoch 22/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 1.0174\n",
      "Epoch 00022: loss improved from 1.09826 to 1.01740, saving model to weights-improvement-22-1.0174-bigger.hdf5\n",
      "114/114 [==============================] - 40s 354ms/step - loss: 1.0174\n",
      "Epoch 23/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.9408\n",
      "Epoch 00023: loss improved from 1.01740 to 0.94077, saving model to weights-improvement-23-0.9408-bigger.hdf5\n",
      "114/114 [==============================] - 40s 351ms/step - loss: 0.9408\n",
      "Epoch 24/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.8664\n",
      "Epoch 00024: loss improved from 0.94077 to 0.86637, saving model to weights-improvement-24-0.8664-bigger.hdf5\n",
      "114/114 [==============================] - 40s 351ms/step - loss: 0.8664\n",
      "Epoch 25/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.8045\n",
      "Epoch 00025: loss improved from 0.86637 to 0.80451, saving model to weights-improvement-25-0.8045-bigger.hdf5\n",
      "114/114 [==============================] - 40s 350ms/step - loss: 0.8045\n",
      "Epoch 26/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.7393\n",
      "Epoch 00026: loss improved from 0.80451 to 0.73932, saving model to weights-improvement-26-0.7393-bigger.hdf5\n",
      "114/114 [==============================] - 40s 352ms/step - loss: 0.7393\n",
      "Epoch 27/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.6769\n",
      "Epoch 00027: loss improved from 0.73932 to 0.67694, saving model to weights-improvement-27-0.6769-bigger.hdf5\n",
      "114/114 [==============================] - 40s 353ms/step - loss: 0.6769\n",
      "Epoch 28/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.6166\n",
      "Epoch 00028: loss improved from 0.67694 to 0.61656, saving model to weights-improvement-28-0.6166-bigger.hdf5\n",
      "114/114 [==============================] - 40s 353ms/step - loss: 0.6166\n",
      "Epoch 29/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.5574\n",
      "Epoch 00029: loss improved from 0.61656 to 0.55737, saving model to weights-improvement-29-0.5574-bigger.hdf5\n",
      "114/114 [==============================] - 40s 350ms/step - loss: 0.5574\n",
      "Epoch 30/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.5312\n",
      "Epoch 00030: loss improved from 0.55737 to 0.53120, saving model to weights-improvement-30-0.5312-bigger.hdf5\n",
      "114/114 [==============================] - 40s 353ms/step - loss: 0.5312\n",
      "Epoch 31/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.4827\n",
      "Epoch 00031: loss improved from 0.53120 to 0.48268, saving model to weights-improvement-31-0.4827-bigger.hdf5\n",
      "114/114 [==============================] - 40s 354ms/step - loss: 0.4827\n",
      "Epoch 32/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.4429\n",
      "Epoch 00032: loss improved from 0.48268 to 0.44292, saving model to weights-improvement-32-0.4429-bigger.hdf5\n",
      "114/114 [==============================] - 40s 351ms/step - loss: 0.4429\n",
      "Epoch 33/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.3984\n",
      "Epoch 00033: loss improved from 0.44292 to 0.39844, saving model to weights-improvement-33-0.3984-bigger.hdf5\n",
      "114/114 [==============================] - 40s 352ms/step - loss: 0.3984\n",
      "Epoch 34/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.3687\n",
      "Epoch 00034: loss improved from 0.39844 to 0.36871, saving model to weights-improvement-34-0.3687-bigger.hdf5\n",
      "114/114 [==============================] - 40s 353ms/step - loss: 0.3687\n",
      "Epoch 35/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.3291\n",
      "Epoch 00035: loss improved from 0.36871 to 0.32907, saving model to weights-improvement-35-0.3291-bigger.hdf5\n",
      "114/114 [==============================] - 40s 353ms/step - loss: 0.3291\n",
      "Epoch 36/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.3005\n",
      "Epoch 00036: loss improved from 0.32907 to 0.30050, saving model to weights-improvement-36-0.3005-bigger.hdf5\n",
      "114/114 [==============================] - 40s 351ms/step - loss: 0.3005\n",
      "Epoch 37/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.2851\n",
      "Epoch 00037: loss improved from 0.30050 to 0.28511, saving model to weights-improvement-37-0.2851-bigger.hdf5\n",
      "114/114 [==============================] - 40s 350ms/step - loss: 0.2851\n",
      "Epoch 38/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.2528\n",
      "Epoch 00038: loss improved from 0.28511 to 0.25278, saving model to weights-improvement-38-0.2528-bigger.hdf5\n",
      "114/114 [==============================] - 40s 352ms/step - loss: 0.2528\n",
      "Epoch 39/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.2401\n",
      "Epoch 00039: loss improved from 0.25278 to 0.24012, saving model to weights-improvement-39-0.2401-bigger.hdf5\n",
      "114/114 [==============================] - 40s 354ms/step - loss: 0.2401\n",
      "Epoch 40/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.2307\n",
      "Epoch 00040: loss improved from 0.24012 to 0.23066, saving model to weights-improvement-40-0.2307-bigger.hdf5\n",
      "114/114 [==============================] - 40s 351ms/step - loss: 0.2307\n",
      "Epoch 41/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1965\n",
      "Epoch 00041: loss improved from 0.23066 to 0.19650, saving model to weights-improvement-41-0.1965-bigger.hdf5\n",
      "114/114 [==============================] - 40s 354ms/step - loss: 0.1965\n",
      "Epoch 42/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1895\n",
      "Epoch 00042: loss improved from 0.19650 to 0.18948, saving model to weights-improvement-42-0.1895-bigger.hdf5\n",
      "114/114 [==============================] - 40s 352ms/step - loss: 0.1895\n",
      "Epoch 43/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1963\n",
      "Epoch 00043: loss did not improve from 0.18948\n",
      "114/114 [==============================] - 40s 353ms/step - loss: 0.1963\n",
      "Epoch 44/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1678\n",
      "Epoch 00044: loss improved from 0.18948 to 0.16779, saving model to weights-improvement-44-0.1678-bigger.hdf5\n",
      "114/114 [==============================] - 40s 351ms/step - loss: 0.1678\n",
      "Epoch 45/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1611\n",
      "Epoch 00045: loss improved from 0.16779 to 0.16108, saving model to weights-improvement-45-0.1611-bigger.hdf5\n",
      "114/114 [==============================] - 40s 351ms/step - loss: 0.1611\n",
      "Epoch 46/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1422\n",
      "Epoch 00046: loss improved from 0.16108 to 0.14224, saving model to weights-improvement-46-0.1422-bigger.hdf5\n",
      "114/114 [==============================] - 40s 351ms/step - loss: 0.1422\n",
      "Epoch 47/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1385\n",
      "Epoch 00047: loss improved from 0.14224 to 0.13854, saving model to weights-improvement-47-0.1385-bigger.hdf5\n",
      "114/114 [==============================] - 40s 351ms/step - loss: 0.1385\n",
      "Epoch 48/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1449\n",
      "Epoch 00048: loss did not improve from 0.13854\n",
      "114/114 [==============================] - 40s 350ms/step - loss: 0.1449\n",
      "Epoch 49/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1306\n",
      "Epoch 00049: loss improved from 0.13854 to 0.13056, saving model to weights-improvement-49-0.1306-bigger.hdf5\n",
      "114/114 [==============================] - 40s 351ms/step - loss: 0.1306\n",
      "Epoch 50/50\n",
      "114/114 [==============================] - ETA: 0s - loss: 0.1156\n",
      "Epoch 00050: loss improved from 0.13056 to 0.11560, saving model to weights-improvement-50-0.1156-bigger.hdf5\n",
      "114/114 [==============================] - 40s 354ms/step - loss: 0.1156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc9a537f610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
