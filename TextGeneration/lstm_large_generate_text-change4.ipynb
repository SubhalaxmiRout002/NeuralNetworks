{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET AND CREATE MAP OF UNIQUE CHARACTERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  7353\n",
      "Total Vocab:  32\n"
     ]
    }
   ],
   "source": [
    "# Load the text corpus\n",
    "filename = \"Cat_in_the_Hat.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "\n",
    "# Convert all the text to lowercase\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "# Create a map that maps each unique character in the text to a unique integer value\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "# Also create a reverse map to be able to output the character that maps to a specific integer\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Display the total number of characters (n_chars) and the vocabulary (the number of unique characters)\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE TRAINING PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  7253\n"
     ]
    }
   ],
   "source": [
    "# Create the patterns to be used for training\n",
    "seq_length = 100 # fixed length sliding window for training pattern\n",
    "dataX = [] # input sequences\n",
    "dataY = [] # outputs\n",
    "\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORM DATA TO BE SUITABLE FOR KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape dataX to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# Rescale integers mapped to characters to the range 0-to-1 to accommodate learning using sigmoid function\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# One hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD THE LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequential model containing 2 LSTM layers and 2 Dropout layers, followed by a dense output layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD THE SAVED NETWORK WEIGHTS FROM CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the network weights from the specified checkpoint file\n",
    "filename = \"weights-improvement-50-0.1156-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "\n",
    "# Compile the model using the Adam optimizer and categorical crossentropy for the loss function\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" ook at this trick,'\n",
      "said the cat.\n",
      "'take a look!'\n",
      "\n",
      "then he got up on top\n",
      "with a tip of his hat.\n",
      "'i ca \"\n",
      "ll this game fun-in-a-box,'\n",
      "said the cat.\n",
      "'in this box are two things\n",
      "i will show to you now.\n",
      "you will like these two things,'\n",
      "said the cat with a bow.\n",
      "\n",
      "'i will pick up the hook.\n",
      "you will see something new.\n",
      "two things. and i call them\n",
      "thing one and thing two.'\n",
      "\n",
      "and sally and i did not know what to say.\n",
      "should we tell her\n",
      "the things that went on there that day?\n",
      "\n",
      "should we tell her about it?\n",
      "now, what should we do?\n",
      "well...\n",
      "what would you do\n",
      "if your mother asked you?\n",
      "ohey want to have fun.'\n",
      "then, o\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Pick a random seed and display it\n",
    "start = numpy.random.randint(0, len(dataX) - 1)\n",
    "\n",
    "pattern = dataX[start]\n",
    "\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# Generate 1000 characters\n",
    "for i in range(500):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "# Text generation complete\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model reduced Charecter 1000 to 500.**\n",
    "\n",
    "The model has 2 LSTM layers and reduced Charecter 1000 to 500.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
